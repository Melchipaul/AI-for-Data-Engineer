{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Querying and Analysis\n",
    "\n",
    "## Table of Contents\n",
    "1. Introduction\n",
    "2. Examples\n",
    "3. References and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 1. Introduction\n",
    "\n",
    "Generative AI can be used in various ways for Natural Language Querying, specifically for converting English to SQL:\n",
    "\n",
    "1. **Direct Translation**: Converting natural language questions into SQL queries.\n",
    "2. **Query Optimization**: Improving existing SQL queries based on natural language descriptions.\n",
    "3. **Schema Understanding**: Interpreting database schemas from natural language descriptions.\n",
    "4. **Error Correction**: Identifying and fixing errors in SQL queries based on natural language feedback.\n",
    "5. 1. Query Translation: Converting natural language questions into formal query languages like SQL.\n",
    "2. Query Generation: Creating complex queries based on high-level descriptions of data needs.\n",
    "3. Result Interpretation: Translating query results into human-readable explanations.\n",
    "4. Schema Understanding: Analyzing database schemas to inform query generation.\n",
    "5. Error Handling: Identifying and explaining errors in queries or results.\n",
    "\n",
    "Using Gen AI for this task offers several benefits:\n",
    "- Increased accessibility for non-technical users\n",
    "- Faster query development\n",
    "- Reduced errors in complex queries\n",
    "- Improved data exploration capabilities\n",
    "\n",
    "**Key Terminology**:\n",
    "- **Natural Language Processing (NLP)**: The branch of AI that deals with the interaction between computers and humans using natural language.\n",
    "- **SQL (Structured Query Language)**: A standard language for managing and manipulating relational databases.\n",
    "- **Schema**: The structure of a database, defining tables, fields, relationships, and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (1.97.1)\n",
      "Requirement already satisfied: pandas in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\data engineering\\ai for data engineer\\ai_data_engineer\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up OpenAI API key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "def clean(dict_variable):\n",
    "    return next(iter(dict_variable.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 1: Simple Query Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"sql\": \"SELECT customer_id, SUM(revenue) AS total_revenue FROM sales GROUP BY customer_id ORDER BY total_revenue DESC LIMIT 5;\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a SQL expert. Convert English queries to SQL.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Convert this English query to SQL and output in JSON form: Find top 5 customers by revenue.\"}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"query\": \"SELECT c.customer_name FROM customer c JOIN sales s ON c.customer_code = s.customer_id GROUP BY c.customer_name ORDER BY SUM(s.sales) DESC LIMIT 5;\"}\n"
     ]
    }
   ],
   "source": [
    "schema = \"\"\"\n",
    "\n",
    "sales\n",
    "order_id\n",
    "customer_id\n",
    "sales\n",
    "\n",
    "customer\n",
    "customer_code\n",
    "customer_name\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a SQL expert. Convert English queries to SQL.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Convert this English query to SQL and output in JSON form: Find top 5 customers (customer names) by sales. The schema of this database is: {}\".format(schema)}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how Gen AI can convert a simple English query into SQL. The JSON output makes it easy for data engineers to parse and integrate the result into their workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 2. Example 2: Query Optimization and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimized_query': \"SELECT o.* FROM orders o JOIN customers c ON o.customer_id = c.customer_id WHERE o.order_date > '2023-01-01' AND c.country = 'USA';\", 'explanation': 'This query uses a JOIN instead of a subquery for better performance on large datasets. JOINs are typically more efficient than IN clauses, especially when dealing with larger tables, as they leverage indexed columns effectively.'}\n"
     ]
    }
   ],
   "source": [
    "bad_query = \"\"\"\n",
    "SELECT * FROM orders WHERE order_date > '2023-01-01' AND customer_id IN (SELECT customer_id FROM customers WHERE country = 'USA')\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a SQL expert. Optimize SQL queries based on natural language descriptions.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Optimize this SQL query and output in JSON form: {} Optimization goal: Improve performance for a large dataset.\".format(bad_query)}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_query = \"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT c3.id, c3.date, c3.amt, c3.prod_name, c3.region, e.emp_name\n",
    "    FROM region c3\n",
    "    JOIN employees e ON c3.id = e.id\n",
    "    WHERE e.active = 1\n",
    ") AS subquery\n",
    "JOIN (\n",
    "    SELECT AVG(s.amt) AS avg_amt\n",
    "    FROM sales s\n",
    ") AS subquery2 ON subquery.amt > subquery2.avg_amt;\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a SQL expert. Given a SQL query, make it more readable. You may split the query into multiple steps with temp tables, and add naming conventions / column names. \\\n",
    "            Avoid complex joins and nested CTEs.\"},\n",
    "        {\"role\": \"user\", \"content\": \"make it more readable. You may split the query into multiple steps with temp tables, and add naming conventions / column names. \\\n",
    "            Avoid complex joins and nested CTEs. Output in JSON form: {}\".format(bad_query)}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "good_query = clean(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'temp_table': 'active_employees',\n",
       "  'query': 'SELECT e.id, e.emp_name FROM employees e WHERE e.active = 1'},\n",
       " {'temp_table': 'region_with_employees',\n",
       "  'query': 'SELECT c3.id, c3.date, c3.amt, c3.prod_name, c3.region, ae.emp_name FROM region c3 JOIN active_employees ae ON c3.id = ae.id'},\n",
       " {'temp_table': 'average_sales',\n",
       "  'query': 'SELECT AVG(s.amt) AS avg_amt FROM sales s'},\n",
       " {'final_query': 'SELECT rwe.id, rwe.date, rwe.amt, rwe.prod_name, rwe.region, rwe.emp_name FROM region_with_employees rwe JOIN average_sales as avg ON rwe.amt > avg.avg_amt'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temp_table_name': 'active_employees', 'sql': 'SELECT e.id, e.emp_name FROM employees e WHERE e.active = 1;'}\n",
      "----\n",
      "{'temp_table_name': 'region_with_employees', 'sql': 'SELECT r.id, r.date, r.amt, r.prod_name, r.region, ae.emp_name FROM region r JOIN active_employees ae ON r.id = ae.id;'}\n",
      "----\n",
      "{'temp_table_name': 'average_sales', 'sql': 'SELECT AVG(s.amt) AS avg_amt FROM sales s;'}\n",
      "----\n",
      "{'final_query': 'SELECT rwe.*, avg.avg_amt FROM region_with_employees rwe JOIN average_sales avg ON rwe.amt > avg.avg_amt;'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for g in good_query:\n",
    "    print (g)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 3: Query Result Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query result provides a breakdown of total sales across five product categories. Here's a detailed interpretation and insights based on these results:\n",
      "\n",
      "### 1. **Highest Performing Category: Electronics**\n",
      "   - **Sales:** $1,500,000\n",
      "   - **Insights:** Electronics significantly outperformed all other categories, generating more than 1.5 times the sales of the next highest category, Clothing. This could indicate a strong consumer demand for electronic products, potential market trends towards gadgets and technology, or effective promotional strategies in this category. \n",
      "\n",
      "### 2. **Second Place: Clothing**\n",
      "   - **Sales:** $980,000\n",
      "   - **Insights:** Clothing sales are substantial but comparatively lower than electronics. This sector may be influenced by seasonal trends, fashion cycles, and consumer preferences. A consistent marketing strategy, such as seasonal sales or promotions, could further boost this category.\n",
      "\n",
      "### 3. **Home & Garden**\n",
      "   - **Sales:** $750,000\n",
      "   - **Insights:** This category shows strong potential as well, but it falls significantly behind clothing. Factors such as home improvement trends or seasonal demands (e.g., spring gardening) can impact sales here. Additionally, exploring partnerships or offers that tap into lifestyle and home decor trends might enhance sales.\n",
      "\n",
      "### 4. **Books**\n",
      "   - **Sales:** $320,000\n",
      "   - **Insights:** Sales in the book category are relatively modest, which could reflect a broader trend of declining print book sales in favor of digital alternatives. However, the ongoing popularity of specific genres, bestsellers, or the rise of audiobooks could create opportunities for growth.\n",
      "\n",
      "### 5. **Lowest Sales: Toys**\n",
      "   - **Sales:** $280,000\n",
      "   - **Insights:** The toy category has the lowest sales figures. This could be due to various factors, such as market saturation, shifts in consumer interest, or competition from digital entertainment options. Marketing strategies that target seasonal peaks (e.g., holiday seasons or birthdays) or collaborations with popular brands or movies might enhance visibility and sales.\n",
      "\n",
      "### **Overall Insights:**\n",
      "- **Market Focus:** Given the dominance of electronics, businesses may want to focus marketing efforts and inventory toward expanding product offerings in this category while also finding ways to invigorate sales in other sectors, particularly home & garden and toys.\n",
      "- **Cross-Promotional Opportunities:** There may be opportunities to create bundles that combine products from different categories (e.g., books with electronics like e-readers) to encourage higher sales volumes.\n",
      "- **Targeted Promotions:** Seasonal promotions, targeted advertisements, and understanding customer demographics can help boost sales in lower-performing categories like Toys and Books.\n",
      "- **Consumer Trends:** Monitoring consumer trends will be vital, particularly for categories like Electronics and Clothing, which are subject to rapid changes in preferences due to technology advancements and fashion trends.\n",
      "\n",
      "### Conclusion:\n",
      "The data underscores the importance of a diversified product strategy, focusing on strengths while addressing weaknesses. Leveraging insights from sales data can help inform decisions around inventory, marketing strategies, and potentially future product development.\n"
     ]
    }
   ],
   "source": [
    "# Simulated query result\n",
    "query_result = \"\"\"\n",
    "| product_category | total_sales |\n",
    "|-------------------|-------------|\n",
    "| Electronics      | 1500000     |\n",
    "| Clothing         | 980000      |\n",
    "| Home & Garden    | 750000      |\n",
    "| Books            | 320000      |\n",
    "| Toys             | 280000      |\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Interpret the following query result and provide insights. Here's the result:\\n{query_result}\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 2. Example 4: Generating Insights from Query Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three relevant follow-up questions for further analysis based on the query result:\n",
      "\n",
      "1. **What are the trends in sales over time for each category?**\n",
      "   - Understanding how sales have changed over different time periods (monthly, quarterly, yearly) could provide insights into seasonality, consumer behavior, and potential areas for growth or decline.\n",
      "\n",
      "2. **How do customer demographics and preferences differ across these categories?**\n",
      "   - Analyzing whether certain demographics (age, gender, location) are more likely to purchase from specific categories can help tailor marketing strategies and product offerings.\n",
      "\n",
      "3. **What are the top-selling products within each category, and what factors contribute to their success?**\n",
      "   - Identifying which specific products are driving sales within each category could reveal consumer preferences and key trends, as well as inform inventory and marketing decisions.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Based on the following query result, suggest 3 relevant follow-up questions for further analysis:\n",
    "{\n",
    "  \"category\": [\"Electronics\", \"Clothing\", \"Books\"],\n",
    "  \"total_sales\": [500000, 300000, 100000]\n",
    "}\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how Gen AI can assist in query optimization, a crucial skill for data engineers working with large datasets and complex database structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "## 3. References and Further Reading\n",
    "\n",
    "1. OpenAI API Documentation: https://platform.openai.com/docs/\n",
    "2. \"Natural Language to SQL: A Survey\" by Xu et al. (2022): https://arxiv.org/abs/2201.00307\n",
    "3. \"Improving Text-to-SQL Evaluation Methodology\" by Zhong et al. (2020): https://arxiv.org/abs/1806.09029\n",
    "4. SQL Performance Tuning by Peter Gulutzan and Trudy Pelzer\n",
    "5. \"Fundamentals of Database Systems\" by Ramez Elmasri and Shamkant Navathe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_data_engineer (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
